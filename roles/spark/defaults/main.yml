stat_file: "/etc/spark.installed"
spark:
  version: 3.0.1
  hadoop_version: without-hadoop
  hadoop_home: /usr/local/hadoop
  java_home: ""
  working_dir: /tmp/spark/data
  install_dir: /opt
  install_temp_dir: /tmp/ansible-install
  eventlog_dir: /tmp/spark-events
  master_port: 7077
  worker_work_port: 65000
  master_ui_port: 8080
  worker_ui_port: 8085
  download_location: https://archive.apache.org/dist/spark/
  user: "spark" # the name of the (OS)user created for spark
  user_groups: [] # Optional list of (OS)groups the new spark user should belong to
  user_shell: "/bin/false" # the spark user's default shell

  env_extras: {}
  defaults_extras:
    "spark.yarn.stagingDir": "hdfs://{{ private_ipv4_addresses[0] }}:54310/"
    "spark.eventLog.enabled": "true"
    "spark.eventLog.dir": "/tmp/spark-events"
    "spark.eventLog.rolling.enabled": "true"
    "spark.ui.enabled": "true"
    "spark.ui.port": "4040"
